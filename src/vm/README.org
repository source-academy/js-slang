** Overview
This concurrent system consists of concurrently executing (potentially multiple) code in multiple threads. Communication between threads is achieved by updating the values of memory shared between threads. Each thread is a nullary function, so the concurrent system executes each thread by running the code in the body of the nullary function.

The design of this system is inspired by [[https://doi.org/10.1007/978-1-4757-3472-0_2][Dijkstra's =cobegin= / =coend= constructs]], of which a good overview and comparison with =fork= / =join= can be found in section 7.2.2 of [[https://doi.org/10.1145/359576.359585][Hoare's Communicating Sequential Processes]].

However, this design departs from Dijkstra's constructs, as the system does not execute parallel threads. Instead, it executes concurrent threads.

** Usage
This concurrent system provides three primitive functions:
0. =concurrent_execute(f_1, ... ,f_n)=, where =f_1, ... ,f_n= are nullary functions.
0. =test_and_set(l)=, where =l= is a list, whose head is a boolean.
0. =clear(l)=, where =l= is a list, whose head is a boolean.

An example using these three functions is:
#+BEGIN_SRC
let x = 0;
let y = 0;
function make_mutex() {
    const cell = list(false);
    function the_mutex(m) {
        return m === "acquire"
               ? (test_and_set(cell)
                 ? the_mutex("acquire")
                 : true )
               : m === "release"
                 ? clear(cell)
                 : error("Unknown request in mutex", m); }
    return the_mutex;
}
const m = make_mutex();

function f() {
    for (let i = 0; i < 100; i = i + 1) {
        m("acquire");
        x = x + 1;
        m("release");
    }
}

function g() {
    for (let i = 0; i < 100; i = i + 1) {
        y = y + 1;
    }
}

concurrent_execute(f, f, f);
concurrent_execute(g, g, g);
display(x);
display(y);
#+END_SRC

** =EXECUTE= Rules

*** Notes
- for simplicity, heap is not represented in the rules
- =g= represents garbage value: its value is not important to the rule

*** Compiling
#+BEGIN_SRC
E1 -> s1 ... En -> sn
---------
concurrent_execute(E1, ... ,En) -> s1. ... .sn.EXECUTE n
#+END_SRC
Each of =s1. ... .sn= is a string of VM instruction that loads a closure onto the operand stack.

*** Running
There are additional structures in our VM:
- =tq=, a register which is a queue of thread suspensions
- =to=, a register initialized with =0=, that indicates how many instructions are left for a thread to run
- =seq=, a register initialized with =<>=, that represents an empty sequential runtime stack. When entering the concurrent context, =os=, =pc=, =e=, and =rs= are copied onto =seq=, and when exiting the concurrent context, they are popped from =seq=.
The tuple representing our VM will have three more corresponding structures:
#+BEGIN_SRC
(os, pc, e, rs, tq, to, seq)
#+END_SRC

**** Starting =EXECUTE=, loading thread frames into register =tq=
#+BEGIN_SRC
s(pc) = EXECUTE n
---------
(((<>, pc1, e1).<>). ... .((<>, pcn, en).<>).os, pc, e, rs, <>, 0, <>) -> (g, <>, g, g, ((<>, pc1, e1).<>). ... .((<>, pcn, en).<>), 0, (os, pc+1, e).rs)
#+END_SRC
Each thread is a four-tuple of =os=, =pc=, =e=, and =rs=. Initially, threads have empty =os= and empty =rs=. Note the transition from empty =seq= to nonempty =seq=: this disambiguates concurrent execution rules from sequential execution rules, so that we know we are executing in the concurrent context.

**** Beginning thread execution
#+BEGIN_SRC
---------
(g, <>, g, g, ((os, pc, e).trs).tq, 0, seq) -> (os, pc, e, trs, tq, c, seq)
#+END_SRC
where =c= is a constant timeout value. Note: =pc= is =<>= to disambiguate this rule from the thread timeout rule.

**** Running thread
#+BEGIN_SRC
s(pc) /= RET /\ to > 0
---------
(os, pc, e, trs, tq, to, seq) -> (os', pc', e', trs', tq, to-1, seq)
#+END_SRC
where the primed values are just like normal VM code execution.

**** Running thread, returning from function
#+BEGIN_SRC
s(pc) = RET /\ to > 0 /\ trs /= <>
---------
(os, pc, e, trs, tq, to, seq) -> (os', pc', e', trs', tq, to-1, seq)
#+END_SRC
where the primed values are just like normal VM code execution. Note: the thread may execute the =RET= statement inside a function, and the thread does the normal thing of popping =trs= and so on.

**** Thread timeout
#+BEGIN_SRC
---------
(os, pc, e, trs, tq, 0, seq) -> (g, <>, g, g, tq.((os, pc, e).trs), 0, seq)
#+END_SRC
When a thread times out and has not finished execution (has not executed the =RET= statement), then it is queued on the thread queue.

**** Returning from thread
#+BEGIN_SRC
s(pc) = RET /\ to > 0 /\ trs = <>
---------
(os, pc, e, trs, tq, to, seq) -> (g, <>, g, g, tq, 0, seq)
#+END_SRC
When a thread executes the =RET= statement, and there are no more thread runtime stacks, the thread is not added back to the thread queue,

**** Ending =EXECUTE=
#+BEGIN_SRC
---------
(g, <>, g, g, <>, 0, (os, pc, e).rs) -> (os, pc, e, rs, <>, 0, <>)
#+END_SRC
When the thread queue is empty, we restore normal sequential execution.

** =TEST_AND_SET= and =CLEAR= Rules

*** Notes

- for simplicity, =e=, =rs=, =p=, =n= and =seq= registers, and heap are not represented in the rules
- =test_and_set= is an atomic operation

*** Compiling
#+BEGIN_SRC
E -> s
---------
test_and_set(E) -> s.TEST_AND_SET
#+END_SRC
where =E= is a list, whose head is a boolean.

#+BEGIN_SRC
E -> s
---------
clear(E) -> s.CLEAR
#+END_SRC
where =E= is a list, whose head is a boolean.

*** Running

#+BEGIN_SRC
s(pc) = TEST_AND_SET
---------
(p.os, pc) -> (b.os, pc+1)
#+END_SRC
where =p= is the address of a list stored on the heap. The head of this list is initially =b=, where =b= is a boolean. After this rule executes, the head of this list is set to =true=.

#+BEGIN_SRC
s(pc) = CLEAR
---------
(p.os, pc) -> (os, pc+1)
#+END_SRC
where =p= is the address of a list stored on the heap. The head of this list is updated to =false=.
