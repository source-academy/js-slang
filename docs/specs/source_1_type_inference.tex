\input source_header.tex

\newcommand{\Rule}[2]{\genfrac{}{}{0.7pt}{}{{\setlength{\fboxrule}{0pt}\setlength{\fboxsep}{3mm}\fbox{$#1$}}}{{\setlength{\fboxrule}{0pt}\setlength{\fboxsep}{3mm}\fbox{$#2$}}}}

\newcommand{\TruE}{\textbf{\texttt{true}}}
\newcommand{\FalsE}{\textbf{\texttt{false}}}
\newcommand{\AndOp}{\texttt{\&\&}}
\newcommand{\OrOp}{\texttt{||}}
\newcommand{\ThenOp}{\texttt{?}}
\newcommand{\ElseOp}{\texttt{:}}
\newcommand{\Rc}{\texttt{\}}}
\newcommand{\Lc}{\texttt{\{}}
\newcommand{\Rp}{\texttt{)}}
\newcommand{\Lp}{\texttt{(}}
\newcommand{\Fun}{\textbf{\texttt{function}}}
\newcommand{\Let}{\textbf{\texttt{let}}}
\newcommand{\Return}{\textbf{\texttt{return}}}
\newcommand{\Const}{\textbf{\texttt{const}}}
\newcommand{\If}{\textbf{\texttt{if}}}
\newcommand{\Else}{\textbf{\texttt{else}}}
\newcommand{\Bool}{\texttt{bool}}
\newcommand{\Number}{\texttt{number}}
\newcommand{\String}{\texttt{string}}
\newcommand{\Undefined}{\texttt{undefined}}
\newcommand{\Pred}{\textit{Pred}}
\newcommand{\type}{\textit{type}}
\newcommand{\polytype}{\textit{polytype}}
\newcommand{\predtype}{\textit{predtype}}
\newcommand{\ExtractPos}{\ensuremath{\textit{Extract}^+}}
\newcommand{\ExtractNeg}{\ensuremath{\textit{Extract}^-}}

\newtheorem{definition}{Definition}[section]

\begin{document}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\docheader{2021}{Source}{\S 1 Type Inference}{Martin Henz, K Muruges, Raynold Ng, Daryl Tan, Tse Hiu Fung}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section{Notation}  

\subsection{The language Source \S 1}

The set of expressions $E$ is the least set that satisfies the following rules, 
where $x$ ranges over a set of names $V$, $n$ ranges over the positive integers, 
$p_1$ ranges over the set of unary primitive operations 
$P_1 = \{$\verb#!#$\}$, and $p_2$ ranges over the set of binary 
primitive operations
$P_2 = \{$\verb@||@,\verb#&&#,\verb#+#,
\verb#-#,\verb#*#,\verb#/#, \verb#%#, \verb#===#,\verb#!==#,\verb#>#,\verb#<#, \verb#<=#, \verb#>=#$\}$.

$\Rule{}{x}$
\hfill 
$\Rule{}{i}$
\hfill 
$\Rule{}{s}$
\hfill 
$\Rule{}{\TruE}$
\hfill 
$\Rule{}{\FalsE}$
\hfill 
$\Rule{}{\Undefined}$

$\Rule{E}{p_1[E]}$
\hfill
$\Rule{E_1\quad E_2}{p_2[E_1, E_2]}$
\hfill
$\Rule{E \qquad E_1 \qquad E_2}{E\ \texttt{?}\ E_1\ \texttt{:}\ E_2}$
\hfill
$\Rule{E\quad E_1\quad \cdots \quad E_n}{E\ \Lp\ E_1\texttt{,}\cdots\texttt{,} E_n\Rp}$

The letters $x$, $i$ and $s$ stand for names, numbers, strings, respectively.

The set of statements is 
the least set that satisfies the
following seven rules.

$\Rule{S}{\Fun\ f \Lp x_1,\cdots, x_n\Rp\ \Lc\ S\ \Rc}$
\hfill
$\Rule{E}{\Let\ x\ \texttt{=}\ E\ \texttt{;}}$
\hfill
$\Rule{E}{\Return\ E\ \texttt{;}}$

\noindent
The identifiers $x_1,\ldots,x_n$ must be pairwise distinct.

$\Rule{S_1 \qquad S_2}{S_1\ S_2}$
\hfill
$\Rule{E}{E\ \texttt{;}}$
\hfill
$\Rule{S}{\Lc\ S\ \Rc}$
\hfill
$\Rule{E \quad S_1\ \quad S_2}{\texttt{if (}\ E \ \texttt{) \{}\ S_1\ \texttt{\} else \{}\ S_2\ \texttt{\}}}$

\noindent
We introduce the following additional rule for expressions, in order
to define functions.

\[ \Rule{S}{\Lp x_1,\cdots, x_n\Rp\ \texttt{=>}\ \Lc\ S\ \Rc} \]

\noindent
We treat function declaration statements of the form
%
\[ \Fun\ f \Lp x_1,\cdots, x_n\Rp\ \Lc\ S\ \Rc \]
%
\noindent
as abbreviations for constant declaration statements as follows
%
\[ \Const\ f\ \texttt{=}\ \Lp x_1,\cdots, x_n\Rp\ \texttt{=>}\ \Lc\ S\ \Rc \texttt{;} \]
%
function definitions of the form 
%
\[ \Lp x_1,\cdots, x_n\Rp\ \texttt{=>}\ E \]
%
\noindent
as abbreviations for the following
%
\[ \Lp x_1,\cdots, x_n\Rp\ \texttt{=>}\ \Lc\ \Return\ E\ \texttt{;}\ \Rc \]
%
Conditional statements of the form 
\begin{lstlisting}
if (x1) {
    const x = 1;    
} else if (x2) {
    const y = 3;
} else if (x3) {
    const a = 3;
} else {
    const b = 3;
}
\end{lstlisting}
\noindent
are treated as abbreviations for the following
\begin{lstlisting}
if (x1) {
    const x = 1;    
} else {
    if (x2) {
        const y = 3;
    } else {
        if (x3) {
            const a = 3;
        } else {
            const b = 3;
        }
    }
}
\end{lstlisting}
  
\subsection{A Language of Types}
\label{simpltyped}

We introduce the following language of types for type inference:

\[
\Rule{}{T_i\ \type}
\qquad
\Rule{}{A_i\ \type}
\]

\[
\Rule{}{\Number\ \type}
\qquad
\Rule{}{\Bool\ \type}
\qquad
\Rule{}{\String\ \type}
\qquad
\Rule{}{\Undefined\ \type}
\]

\[ \Rule{t_1\ \type \quad \cdots\quad t_n\ \type\quad t\ \type}{(t_1, \ldots t_n) \rightarrow t\ \type}
\]

\[
\Rule{t\ \type}{\forall ( t )\ \polytype}
\qquad
\Rule{t\ \polytype}{\Pred(t)\ \predtype}
\qquad
\Rule{t\ \type}{\Pred(t)\ \predtype}
\]

\noindent
where $n \geq 1$, and $T_i$ and $A_i$ represent type variables. We will capitalize 
type variables, as in $T_1, A_2$. We will also refer to the types in the second row (i.e. $\Bool$,
$\Undefined$, $\Number$, $\String$) as \emph{base types}. The symbols $t_i$ in the rules above
are meta-variables that stand for types and must not be confused with type variables
that \emph{are} types.
As usual, parentheses can be used in practice for grouping.
Examples of valid types are $\Number$ and
$(\Number, () \rightarrow \Bool, \Undefined, T_1) \rightarrow (\Bool \rightarrow A_2)$.

Types of the form $\Pred ( t )$ are called \emph{predicate types},
types of the form $\forall ( t )$ are called \emph{polymorphic types},
and all other are called \emph{monomorphic types}.

We distinguish two kinds of type variables, $T_i$ and $A_i$, to be able to handle
the overloading of operators such as \texttt{+} (for numbers and strings).
A type variable $A_i$ can only
represent ``addable'' types, i.e. 
$\Number$ or $\String$, and
a type variable $T_i$ can represent any type.

\subsection{Type Environments}

For Source, well-typedness of an statement depends on the context in which the
statement appears. The expression \verb#x + 3# within a statement may or may 
not be well-typed, depending on the type of \verb#x#. Thus in order 
to formalize the notion of a context, we define a 
\emph{type environment}, denoted by $\Gamma$, that keeps track
of the type of names appearing in the statement. More
formally,
the partial function $\Gamma$ from names to types expresses a 
context, in which a name $x$ is associated with type $\Gamma(x)$. 

We define a relation $\Gamma[x \leftarrow t]\Gamma'$ on type environments 
$\Gamma$, names $x$, types $t$, and type environments $\Gamma'$,
which constructs a type environment that behaves like the 
given one, except that the type of $x$ is $t$. More formally, 
if $\Gamma[x \leftarrow t]\Gamma'$, then $\Gamma'(y)$ is $t$, 
if $y=x$ and $\Gamma(y)$ 
otherwise. Obviously, this uniquely identifies $\Gamma'$ for
a given $\Gamma$, $x$, and $t$, and thus the type environment extension
relation is functional in its first three arguments.

The set of names, on which a type environment
$\Gamma$ is defined, is called the domain of $\Gamma$, 
denoted by $\textit{dom}(\Gamma)$.

%Note that we used the same notation $\cdot [ \cdot \leftarrow \cdot ]\cdot$
%to denote substitution in Section~6.2. It will
%always be clear from the context, which operation is meant.

For each non-overloaded primitive operator, we add a binding to our initial
type environment $\Gamma_0$ as follows:

\begin{eqnarray*}
& &
       \emptyset[ -_2 \leftarrow  (\Number, \Number) \rightarrow \Number]\\
&& \hspace{2mm} [ * \leftarrow  (\Number, \Number) \rightarrow \Number]\\
&& \hspace{2mm} [ / \leftarrow  (\Number, \Number) \rightarrow \Number]\\
&& \hspace{2mm} [ \% \leftarrow (\Number, \Number) \rightarrow \Number]\\
&& \hspace{2mm} [ \&\& \leftarrow \forall((\Bool, \Bool) \rightarrow \Bool)]\\
&& \hspace{2mm} [ || \leftarrow   \forall((\Bool, \Bool) \rightarrow \Bool)]\\
&& \hspace{2mm} [ ! \leftarrow \Bool \rightarrow \Bool]\\
&& \hspace{2mm} [ -_1 \leftarrow \Number \rightarrow \Number]\Gamma_{-2}
\end{eqnarray*}

The overloaded binary primitive are handled as follows:

\begin{eqnarray*}
 & &
      \Gamma_{-2}
                 [ \texttt{+} \leftarrow \forall((A, A) \rightarrow A)] \\
&& \hspace{6mm}  [ \texttt{===} \leftarrow \forall((A, A) \rightarrow \Bool)] \\
&& \hspace{6mm}  [ \texttt{!==} \leftarrow \forall((A, A) \rightarrow \Bool)] \\
&& \hspace{6mm}  [ \texttt{>} \leftarrow \forall((A, A) \rightarrow \Bool)]\\
&& \hspace{6mm}  [ \texttt{>=} \leftarrow \forall((A, A) \rightarrow \Bool)]\\
&& \hspace{6mm}  [ \texttt{<} \leftarrow \forall((A, A) \rightarrow \Bool)] \\
&& \hspace{6mm}  [ \texttt{<=} \leftarrow \forall((A, A) \rightarrow \Bool)]\Gamma_{-1}
\end{eqnarray*}

\begin{tabular}[fragile]{lllllllll}
$\Gamma_{-1}$
& $[$ & \texttt{display}      & $\leftarrow$  & $\forall(T)$ & & & $]$ \\
& $[$ & \texttt{error}      & $\leftarrow$  & $\forall(T)$ & & & $]$ \\
& $[$ & \texttt{Infinity}      & $\leftarrow$  & $\Number$ & & & $]$ \\
& $[$ & \texttt{is\_boolean}   & $\leftarrow$  & $\Pred(\Bool)$ & & & $]$ \\
& $[$ & \texttt{is\_function}  & $\leftarrow$  & $\Pred(\forall(T_1$ & $\rightarrow$ & $T_2))$ & $]$ \\
& $[$ & \texttt{is\_number}    & $\leftarrow$  & $\Pred(\Number)$ & & & $]$ \\
& $[$ & \texttt{is\_string}    & $\leftarrow$  & $\Pred(\String)$ & & & $]$ \\
& $[$ & \texttt{is\_undefined} & $\leftarrow$  & $\Pred(\Undefined)$ & & & $]$ \\
& $[$ & \texttt{math\_abs} & $\leftarrow$  & $\Number$ & $\rightarrow$ & $\Number$ & $]$ \\
& $[$ & \texttt{math\_acos} & $\leftarrow$  & $\Number$ & $\rightarrow$ & $\Number$ & $]$ \\
& $[$ & \texttt{math\_acosh} & $\leftarrow$  & $\Number$ & $\rightarrow$ & $\Number$ & $]$ \\
& $[$ & \texttt{math\_asin} & $\leftarrow$  & $\Number$ & $\rightarrow$ & $\Number$ & $]$ \\
& $[$ & \texttt{math\_asinh} & $\leftarrow$  & $\Number$ & $\rightarrow$ & $\Number$ & $]$ \\
& $[$ & \texttt{math\_atan} & $\leftarrow$  & $\Number$ & $\rightarrow$ & $\Number$ & $]$ \\
& $[$ & \texttt{math\_atan2} & $\leftarrow$  & $(\Number, \Number)$ & $\rightarrow$ & $\Number$ & $]$ \\
& $[$ & \texttt{math\_atanh} & $\leftarrow$  & $\Number$ & $\rightarrow$ & $\Number$ & $]$ \\
& $[$ & \texttt{math\_cbrt} & $\leftarrow$  & $\Number$ & $\rightarrow$ & $\Number$ & $]$ \\
& $[$ & \texttt{math\_ceil} & $\leftarrow$  & $\Number$ & $\rightarrow$ & $\Number$ & $]$ \\
& $[$ & \texttt{math\_clz32} & $\leftarrow$  & $\Number$ & $\rightarrow$ & $\Number$ & $]$ \\
& $[$ & \texttt{math\_cos} & $\leftarrow$  & $\Number$ & $\rightarrow$ & $\Number$ & $]$ \\
& $[$ & \texttt{math\_cosh} & $\leftarrow$  & $\Number$ & $\rightarrow$ & $\Number$ & $]$ \\
& $[$ & \texttt{math\_exp} & $\leftarrow$  & $\Number$ & $\rightarrow$ & $\Number$ & $]$ \\
& $[$ & \texttt{math\_expm1} & $\leftarrow$  & $\Number$ & $\rightarrow$ & $\Number$ & $]$ \\
& $[$ & \texttt{math\_floor} & $\leftarrow$  & $\Number$ & $\rightarrow$ & $\Number$ & $]$ \\
& $[$ & \texttt{math\_fround} & $\leftarrow$  & $\Number$ & $\rightarrow$ & $\Number$ & $]$ \\
& $[$ & \texttt{math\_hypot} & $\leftarrow$  & $\forall(T)$ & & & $]$ \\
& $[$ & \texttt{math\_imul} & $\leftarrow$  & $(\Number, \Number)$ & $\rightarrow$ & $\Number$ & $]$ \\
& $[$ & \texttt{math\_LN2} & $\leftarrow$  & $\Number$ & & & $]$ \\
& $[$ & \texttt{math\_LN10} & $\leftarrow$  & $\Number$ & & & $]$ \\
& $[$ & \texttt{math\_log} & $\leftarrow$  & $\Number$ & $\rightarrow$ & $\Number$ & $]$ \\
& $[$ & \texttt{math\_log1p} & $\leftarrow$  & $\Number$ & $\rightarrow$ & $\Number$ & $]$ \\
& $[$ & \texttt{math\_log2} & $\leftarrow$  & $\Number$ & $\rightarrow$ & $\Number$ & $]$ \\
& $[$ & \texttt{math\_LOG2E} & $\leftarrow$  & $\Number$ & & & $]$ \\
& $[$ & \texttt{math\_log10} & $\leftarrow$  & $\Number$ & $\rightarrow$ & $\Number$ & $]$ \\
& $[$ & \texttt{math\_LOG10E} & $\leftarrow$  & $\Number$ & & & $]$ \\
& $[$ & \texttt{math\_max} & $\leftarrow$  & $\forall(T)$ & & & $]$ \\
& $[$ & \texttt{math\_min} & $\leftarrow$  & $\forall(T)$ & & & $]$ \\
& $[$ & \texttt{math\_PI} & $\leftarrow$  & $\Number$ & & & $]$ \\
& $[$ & \texttt{math\_pow} & $\leftarrow$  & $(\Number, \Number)$ & $\rightarrow$ & $\Number$ & $]$ \\
& $[$ & \texttt{math\_random} & $\leftarrow$  & $()$ & $\rightarrow$ & $\Number$ & $]$ \\
& $[$ & \texttt{math\_round} & $\leftarrow$  & $\Number$ & $\rightarrow$ & $\Number$ & $]$ \\
& $[$ & \texttt{math\_sign} & $\leftarrow$  & $\Number$ & $\rightarrow$ & $\Number$ & $]$ \\
& $[$ & \texttt{math\_sin} & $\leftarrow$  & $\Number$ & $\rightarrow$ & $\Number$ & $]$ \\
& $[$ & \texttt{math\_sinh} & $\leftarrow$  & $\Number$ & $\rightarrow$ & $\Number$ & $]$ \\
& $[$ & \texttt{math\_sqrt} & $\leftarrow$  & $\Number$ & $\rightarrow$ & $\Number$ & $]$ \\
& $[$ & \texttt{math\_SQRT1\_2} & $\leftarrow$  & $\Number$ & & & $]$ \\
& $[$ & \texttt{math\_SQRT2} & $\leftarrow$  & $\Number$ & & & $]$ \\
& $[$ & \texttt{math\_tan} & $\leftarrow$  & $\Number$ & $\rightarrow$ & $\Number$ & $]$ \\
& $[$ & \texttt{math\_tanh} & $\leftarrow$  & $\Number$ & $\rightarrow$ & $\Number$ & $]$ \\
& $[$ & \texttt{math\_trunc} & $\leftarrow$  & $\Number$ & $\rightarrow$ & $\Number$ & $]$ \\
& $[$ & \texttt{NaN} & $\leftarrow$  & $\Number$ & & & $]$ \\
& $[$ & \texttt{parse\_int} & $\leftarrow$  & $(\String, \Number)$ & $\rightarrow$ & $\Number$ & $]$ \\
& $[$ & \texttt{prompt} & $\leftarrow$  & $\String$ & $\rightarrow$ & $\String$ & $]$ \\
& $[$ & \texttt{get\_time} & $\leftarrow$  & $()$ & $\rightarrow$ & $\Number$ & $]$ \\
& $[$ & \texttt{stringify} & $\leftarrow$  & $\forall(T$ & $\rightarrow$ & $\String)$ & $]$ \\
& $[$ & \texttt{undefined} & $\leftarrow$  & $\Undefined$ & & & $]$ & $\Gamma_0$ \\
& \end{tabular}
 
\subsection{Preparing Programs for Type Inference}

To facilitate the process of type inference, we annotate each component of the given
program with unique type variables and introduce a simple transformation at the toplevel.

A \emph{toplevel transformation} clarifies the nature
of the names declared outside of function definitions,
and the type of the overall statement. The toplevel
transformation wraps the given program into a block, and introduces \lstinline{return}
keywords in front of expression statements, when these are the last statements in a
sequence to be evaluated, even when they occur within conditional statements.

Examples:

\begin{lstlisting}
const x = 1;
x + 2; 
\end{lstlisting}
becomes
\begin{lstlisting}
{
    const x = 1;
    return x + 2;
}    
\end{lstlisting}
and
\begin{lstlisting}
if (true) {
    const x = 1;    
    x + 2;
} else {
    const y = 3;
    y + 4;
}
\end{lstlisting}
becomes
\begin{lstlisting}
{
    if (true) {
        const x = 1;    
        return x + 2;
    } else {
        const y = 3;
        return y + 4;
    }
}
\end{lstlisting}

To facilitate the process of type inference, we annotate each component of the given
program with unique type variables. We write the type variable as a superscript after
the component, and use parentheses for clarification. For example, the Source \S 1
program
\begin{lstlisting}
{ const x = 1; return x + 2; }
\end{lstlisting}
is represented by the annotated program
\[ 
\Const\ \texttt{x}^{T_1}\ \texttt{=}\ 1^{T_2}\texttt{;}\ 
\texttt{return }\ (\texttt{x}^{T_3} \ \texttt{+} \ \texttt{2}^{T_4})^{T_5} \ \texttt{;}
\]

\subsection{Type Constraints}

We introduce type constraints $\Sigma$ as conjunctions of type equations:

$\Rule{}{\top}$
\hfill 
$\Rule{}{t_1 = t_2}$
\hfill 
$\Rule{\Sigma_1 \qquad \Sigma_2}{\Sigma_1 \wedge \Sigma_2}$

\noindent
We require that constraints are kept in \emph{solved form}:
\[
t_1 = t_1' \wedge \cdots \wedge t_i = t_i' \wedge \cdots \wedge t_n = t_n'
\]
where:
\begin{itemize}
\item all $t_i$ are type variables,
\item for any type variable $T_i$, there is at most one equation $T_i = \cdots$,
\item no variable $t_i$ occurs in any equation $t_j = t_j'$ if $j > i$.
\end{itemize}
A constraint in solved form does not have any cycles $t^{(0)} = t^{(1)}, t^{(1)} = t^{(2)}, \ldots, t^{(k)} = t^{(0)}$.
We \emph{apply} a type constraint $\Sigma$ in solved form to a type $t$ as follows:

\[
  \Rule{\textrm{if $t_i$ is a \emph{base type} or }t_i = t_i'\textrm{ does not occur in }\Sigma}{
    \Sigma(t_i) = t_i}
  \qquad
  \Rule{\textrm{if }t_i = t_i'\textrm{ occurs in }\Sigma}{
    \Sigma(t_i) = \Sigma(t_i')}  
\]

\[
  \Rule{t' = \Sigma(t) \qquad t_1' = \Sigma(t_1) \qquad \cdots \qquad t_n' = \Sigma(t_n) }{
  \Sigma((t_1, \ldots, t_n) \rightarrow t) = (t_1', \ldots, t_n') \rightarrow t'}
\]

\noindent
Example: If $\Sigma = (T_1 = \Number \wedge T_2 = T_3 \rightarrow \Bool \wedge T_3 = \Number
\rightarrow \Bool)$, we have $\Sigma(\Number \rightarrow T_2) = \Number \rightarrow ((\Number
\rightarrow \Bool) \rightarrow \Bool)$.

Note that in our framework, type constraints never contain any polymorphic types. Thus
you will never see ``$\forall$'' an a type constraint.

We add a constraint $t = t'$ to a solved form $\Sigma$ by applying the following rules
in the given order:
\begin{itemize}
\item If $t$ is a \emph{base type} and $t'$ is also a \emph{base type} of the same kind, do nothing.
\item If $t$ is not a type variable and $t'$ is a type variable, then we now try to add $t' = t$ to
$\Sigma$, following the same rules.
\item If $t$ is a type variable and $\Sigma(t')$ is a type variable with the same name as $t$, do nothing.
\item If $t$ is a type variable, $\Sigma(t')$ is a function type and $t$ is contained in $\Sigma(t')$, then stop
  with a type error as we will have an infinite type. (e.g. A = B -> A)
\item If $t$ is $A_i$ and $\Sigma(t')$ is not a type variable and not $\Number$ or $\String$,
  then stop with a type error.
\item If $t$ is a type variable and there is an equation $t = t''$ in $\Sigma$, then
  we now try to add the equation $t' = t''$ to $\Sigma$, following the same rules.
\item If $t$ is a type variable that does not occur on the left in any equation in $\Sigma$,
  then add $t = \Sigma(t')$ in the front of $\Sigma$. In addition, if $\Sigma(t)$ is an "addable"
  type variable $A_i$ and $\Sigma(t')$ is a regular type variable $T_j$, we must convert $\Sigma(t')$
  into an "addable" type $A_j$.  
\item If $t$ is $(t_1,\ldots, t_n) \rightarrow t''$ and
  $t'$ is $(t_1',\ldots, t_n') \rightarrow t'''$, then add n constraints
  $t_1 = t_1', \cdots, t_n = t_n', t'' = t'''$ to $\Sigma$, each time going through the above set of rules.
\item Any other case  (e.g. $\Bool = \String$) stops with a type error.
\end{itemize}
This process is guaranteed to terminate either with a type error or with a new solved form.

\section{Typing Relation}

The set of well-typed programs is defined by the binary typing relation
written $S: \Sigma$, where $S$ is a toplevel-transformed, type-annotated program.
The relation is defined using the quaternary typing relation
$\Sigma, \Gamma \vdash S : \Sigma'$, as follows:
$S: \Sigma$ holds if and only if 
$\top, \Gamma_0 \vdash S : \Sigma$
where $\Gamma_0$ is the intial type environment described above and $\top$ is the empty
type constraint. The constraint $\Sigma$ can be called the constraint \emph{inferred from}
$S$. 

We define the typing relation for expressions and statements
inductively with the following rules.

\subsection{Typing Relation on Expressions}

The type of a name needs to be provided by the type environment. The first rule
applies when $\Gamma(x)$ is monomorphic, i.e. $\Gamma(x) \neq \forall t'$.

\noindent
$\Rule{\Gamma(x)\ \type \qquad
  \Sigma' = (\Sigma \wedge t = \Gamma(x))}{\Sigma, \Gamma \vdash x^t : \Sigma'}$

If $\Gamma(x)$ is polymorphic,  i.e. $\Gamma(x) = \forall t'$, we replace all type variables in
$t'$ with fresh type variables:

\noindent
$\Rule{\Gamma(x)\ \polytype \qquad
  \Sigma' = (\Sigma \wedge t = \textit{fresh}(t'))}{\Sigma, \Gamma \vdash x^t : \Sigma'}$

\noindent
where $\textit{fresh}(t')$ results from $t'$ by replacing all type variables consistently with
fresh type variables.

Example: $\textit{fresh}(\Bool \rightarrow (T_1 \rightarrow (T_2 \rightarrow T_2)))$
might return $\Bool \rightarrow (T_{77} \rightarrow (T_{88} \rightarrow T_{88})))$.

If $\Gamma(x)$ is a predicate type,  i.e. $\Gamma(x) = \Pred(t')$,
we treat $x$ as if it had the type $\forall (t_0 \rightarrow \Bool)$ instead:

\noindent
$\Rule{\Gamma(x)\ \predtype \qquad
  (\Sigma \wedge t = \textit{fresh}(t_0) \rightarrow Bool) = \Sigma'}{\Sigma, \Gamma \vdash x^t : \Sigma'}$

\noindent
where $\textit{fresh}(t_0)$ is some fresh type variable.

If $\Gamma(x)$ is not defined, then none of the rules are applicable.
In this case, we say that
there is no type for $x$ derivable from the type environment $\Gamma$. 

Constants get the following types.

\noindent
\[
  \Rule{\Sigma' = (\Sigma \wedge t = \Number)}{\Sigma, \Gamma \vdash n^t : \Sigma'}
  \qquad
  \Rule{\Sigma' = (\Sigma \wedge t = \String)}{\Sigma, \Gamma \vdash s^t : \Sigma'}
\]
\noindent
where $n$ denotes any literal number $s$ denotes any literal string.

\noindent
\[
  \Rule{\Sigma' = (\Sigma \wedge t = \Bool)}{\Sigma, \Gamma \vdash \TruE^t : \Sigma'}
  \quad
  \Rule{\Sigma' = (\Sigma \wedge t = \Bool)}{\Sigma, \Gamma \vdash \FalsE^t : \Sigma'}  
\]

We have the following rule for function application.

\[
\Rule{  \Sigma_0, \Gamma \vdash E_0^{t_0} : \Sigma_1 \quad
	\cdots \quad \Sigma_{n}, \Gamma \vdash E_{n}^{t_n} : \Sigma_{n+1} \quad
	(\Sigma_{n+1} \wedge t_0 = (t_1, \ldots, t_n) \rightarrow t) = \Sigma_{n+2}}{
	\Sigma_0, \Gamma \vdash (E_0^{t_0}\ \Lp \ E_1^{t_1}, \ldots, E_n^{t_n}\ \Rp)^t : \Sigma_{n+2}}  
\]

\noindent
The type of the operator needs to be a function type with the right
number of parameters, and the type of every argument needs to coincide
with the corresponding parameter type of the function type. If all these
conditions are met, the type of the function application is the same
as the return type of the function type that is the type of the operator.

The typing of function definition statements is defined as follows.

\noindent
\[
  \Rule{\Sigma \wedge (t' = (t_1, \ldots, t_n) \rightarrow t), \Gamma[x_1 \leftarrow t_1]\cdots
    [x_n \leftarrow t_n]
    \vdash S^{t} : \Sigma'}{
    \Sigma, \Gamma \vdash ( \Lp  x_1^{t_1}, \ldots, x_n^{t_n} \Rp\ \texttt{=>}\ \Lc\ S^{t}\ \Rc)^{t'} : \Sigma'}  
\]


%% \vspace{5mm}

%% \begin{example}
%% The following proof shows that the typing relation holds for the
%% statement 
%% \[
%% \emptyset \vdash\ \texttt{(fun {int -> int} x -> x+1 end 2)}\ 
%% : \Int
%% \] 
%% The reader may annotate each rule application with the name
%% of the applied rule as in the previous example.

%% \noindent
%% \emph{
%% $\Rule{\Rule{\emptyset[\X \leftarrow \Int]\Gamma\quad\Rule{\Rule{}{\Gamma \vdash \X : \Int}\quad \Rule{}{\Gamma \vdash \texttt{1} : \Int}}{\Gamma \vdash \X\texttt{+}\texttt{1} : \Int}}{\emptyset \vdash \Fun\ \Lc \Int\ \Right\ \Int\Rc\ \X\ \Right\ \X\Plus \texttt{1}\ \End : \Int\ \Right\ \Int} \qquad \Rule{}{\emptyset \vdash \texttt{2} : \Int}}%
%% {\emptyset \vdash \Lp\Fun\ \Lc \Int\ \Right\ \Int\Rc\ \X\ \Right\ \X\Plus \texttt{1}\ \End\ \texttt{2}\Rp  : \Int}$}
%% \end{example}

%% \vspace{5mm}

%% \begin{lemma}\label{typefunction}
%% For every expression $E$ and every type assignment $\Gamma$, 
%% there exists at most one type $t$ such that $\Gamma \vdash E : t$.
%% \end{lemma}
%% \begin{proof}
%% We prove this statement using structural induction over the given expresssion
%% $E$. That means we consider the following property $P$ of Typed Source expressions $E$:
%% \begin{quotation}%
%% \noindent
%% For every type assignment $\Gamma$, there exists at most one type $t$ such
%% that $\Gamma \vdash E : t$ holds.
%% \end{quotation}
%% If we are able to show that this property (taken as a set) meets all
%% rules given for Typed Source expressions $E$, we know that $\textrm{Typed Source} \subseteq P$,
%% which means that every element of Typed Source has the property $P$. So let us look 
%% at the rules defining Typed Source.
%% \begin{itemize}
%% \item $\Rule{}{x}$\\
%% The only typing rule that applies in this case is rule VarT 
%% (page~\pageref{vart}). Since type environments are functions, it is
%% immediately clear that for every type environment $\Gamma$, there
%% can be at most one type for $x$, namely $\Gamma(x)$.
%% \item $\Rule{}{n}$, $\Rule{}{\TruE}$, $\Rule{}{\FalsE}$\\
%% The only typing rules that apply in these cases are the respective rules
%% for typing of constants, NumT, TrueT and FalseT (page~\pageref{numt}).
%% They assign a unique type (\texttt{number} for numbers, \Bool for
%% $\TruE$ and $\FalsE$) to the constant expressions.
%% \item 
%% $\Rule{E}{p_1[E]}$, $\Rule{E_1\quad E_2}{p_2[E_1, E_2]}$\\
%% We need to show that our property $P$ meets the rules for Typed Source primitive
%% operations. For our only unary operation \verb#\#, we need to show:
%% \begin{quotation}%
%% \noindent
%% If for every type assignment $\Gamma$, there exists at most one type $t$ such
%% that $\Gamma \vdash E : t$ holds, then for every type assignment $\Gamma'$,
%% there exists at most one type $t'$ such that $\Gamma' \vdash \texttt{!}[E] : t'$
%% holds.
%% \end{quotation}
%% The only typing rule that applies in this case is the rule Prim$_1$.
%% The only possible type for $\texttt{!}[E]$ according to this rule is
%% \Bool.

%% The argument for the binary primitive operations is similar.
%% \item $\Rule{E \qquad E_1 \qquad E_2}{E\ \texttt{?}\ E_1\ \texttt{:}\ E_2}$\\
%% The only typing rule that applies here is the rule IfT.

%% $\Rule{\Gamma \vdash E : \Bool \qquad \Gamma \vdash E_1 : t \qquad
%%  \Gamma \vdash E_2 : t}{\Gamma \vdash E\ \texttt{?}\ E_1\ \texttt{:}\ E_2 : t}$
%% \textbf{[IfT]} 

%% It is clear from this rule
%% that if there is at most one type $t$ for $E_1$, then there is
%% at most one type for the entire conditional 
%% $E\ \texttt{?}\ E_1\ \texttt{:}\ E_2$, namely the same type $t$.

%% \item $\Rule{E\quad E_1\quad \cdots \quad E_n}{E\ \Lp \ E_1,\cdots, E_n\Rp}$\\
%% The only rule that applies here is the rule ApplT:

%% $\Rule{\Gamma \vdash E : t_1\Times \cdots \Times t_n\ \Right\ t \qquad \Gamma \vdash E_1 : t_1 \quad \cdots \quad \Gamma \vdash E_n : t_n}{\Gamma \vdash E\ \Lp \ E_1,\cdots, E_n\ \Rp : t}$

%% \noindent
%% This rule applies only if $E$ has a type of the form 
%% $t_1\Times \cdots \Times t_n\ \Right\ t$. It is clear from this rule that
%% if there is only one such type 
%% $t_1\Times \cdots \Times t_n\ \Right\ t$ for $E$ for any $\Gamma$, then 
%% there is at most one type for the entire application, namely $t$.

%% \end{itemize}
%% \end{proof}

%% \noindent
%% Since for each expression, there is at most one rule that applies, we 
%% can invert the rules and state the following theorem. 

%% \begin{theorem}~ \\
%% \emph{
%% \begin{enumerate}
%% \item If $\Gamma \vdash  x : t$, then $\Gamma(x) = t$. 
%% \item If $\Gamma \vdash  n : t$, then $t = \texttt{number}$, for any integer $n$,
%% and similarly for \texttt{true} and \texttt{false}. 
%% \item If $\Gamma \vdash E\ \texttt{?}\ E_1\ \texttt{:}\ E_2 : t$, then 
%% $\Gamma \vdash  E : \Bool$, 
%% $\Gamma \vdash  E_1 : t$, and 
%% $\Gamma \vdash  E_2 : t$. 
%% \item If $\Gamma \vdash  E\ \Lp \ E_1, \ldots, E_n\ \Rp : t$, 
%% then there exist types $t_1,\ldots,t_n$ 
%% such that
%% $\Gamma \vdash  E : t_1 \Times \cdots \Times t_n\ \Right\ t$ and 
%% $\Gamma \vdash  E_1 : t_1, \ldots \Gamma \vdash  E_n : t_n$. 
%% \end{enumerate}}
%% \end{theorem}
%% %
%% This theorem means that we can often infer the type of a given expression
%% by looking at the form of the expression. Some programming languages exploit
%% this fact by avoiding (most) type declarations for the user. The programming
%% system carries out type inference and calculates the required type declarations.
%% Type checking for such languages is done at the same time as type inference.

%% \begin{lemma}
%% Substituting a name by an expression of the same type 
%% does not affect typing. 
%% If $\Gamma[x\leftarrow t']\Gamma'$, $\Gamma' \vdash E : t$, 
%% and $\Gamma \vdash E' : t'$, then 
%% $\Gamma \vdash E'' : t$, where $E[x\leftarrow E']E''$.
%% \end{lemma}

\subsection{Typing Relation on Statements}

The following rule deals with the typing of sequences. We assume that
whenever there is a return statement or a conditional statement with a return statement within a
sequence, it is the last statement in the sequence.
(One could consider a ``dead code'' error otherwise.)

\[
\Rule{
  (\Sigma_1 \wedge t_3 = t_2), \Gamma \vdash S_1^{t_1} : \Sigma_2 \qquad 
  \Sigma_2, \Gamma \vdash S_2^{t_2} : \Sigma_3}{
\Sigma_1, \Gamma \vdash (S_1^{t_1}\ S_2^{t_2})^{t_3}  : \Sigma_3}
\]

\noindent
Return statements are typed as follows.
\[
\Rule{
(\Sigma \wedge t' = t), \Gamma \vdash E^{t} : \Sigma' }{
\Sigma, \Gamma \vdash (\Return\ E^{t} \texttt{;})^{t'} : \Sigma'}
\]

\noindent
The type of expression statements is $\Undefined$. Note that expression statements
at toplevel get a return placed in front of them by the toplevel-transformation described above.
\[
\Rule{
(\Sigma \wedge t' = \Undefined), \Gamma \vdash E^{t} : \Sigma' }{
\Sigma, \Gamma \vdash (E^{t} \texttt{;})^{t'} : \Sigma'}
\]

\noindent
For blocks (including the bodies of function definitions), we discern whether the
block contains constant declarations or not. If it does not contain constant
declarations, the typing is easy:

\[
\Rule{
  S\ \textrm{does not contain }\Const \qquad
  (\Sigma \wedge t' = t), \Gamma \vdash S^{t} : \Sigma' }{
\Sigma, \Gamma \vdash \Lc \ S^{t} \ \Rc^{t'}  : \Sigma_3}
\]

\noindent
Blocks (including the bodies of function definitions) that 
contain constant declarations introduce polymorphism. In the following
rule we assume that $S$ does not have any further constant declarations. The rule
is a simplification of the general case, because statements other than constant
declarations can appear before and between the constant declarations. The rule
applies analogously in this case, without re-arranging the statements. This means
that the body of a block has two parts:
\begin{itemize}
\item the part up to and including the last constant declaration, where all
  declared names are monomorphically typed, and
\item the part after the last constant declaration, where all declared names
  are polymorphically typed.
\end{itemize}

\[
\Rule{
  \begin{minipage}{120mm}
    $\Gamma[x_1 \leftarrow t_1]\cdots[x_n \leftarrow t_n]\Gamma' $\\
    $\Sigma_1 = (\Sigma_0 \wedge t = t' \wedge t'_1 = undefined \wedge \cdots \wedge t'_n = undefined)$ \\
    $\Sigma_1, \Gamma' \vdash E_1^{t_1} : \Sigma_2 \cdots
     \Sigma_n, \Gamma' \vdash E_n^{t_n} : \Sigma_{n+1}$\\
    $\Gamma'[x_1 \leftarrow \forall \Sigma_{n+1}(t_1)]\cdots[x_n \leftarrow \forall \Sigma_{n+1}(t_n)]\Gamma'' $\\
    $\Sigma_{n+1}, \Gamma'' \vdash S^t : \Sigma_{n+2}$
  \end{minipage}
}{
  \Sigma_0, \Gamma \vdash \Lc\
  (\Const\ x_1 \ \texttt{=}\ E_1^{t_1} \texttt{;)}^{t'_1} \texttt{ } \cdots \texttt{ }
  (\Const\ x_n \ \texttt{=}\ E_n^{t_n} \texttt{;)}^{t'_n} \texttt{ } \ S^t \Rc^{t'} : \Gamma_{n+2}
}
\]


\subsection{Typing Relation on Conditionals}

For the typing of conditional expressions and conditional statements,
the idea is that if the condition is a ``predicate test'',
then in the consequent branch, we should assert that the variable has the appropriate type.
It's easier to understand with an example:

\begin{lstlisting}
function id(x) {
    if (is_number(x)) {
        return x + 0;
    } else {
        return x;
    }
}
\end{lstlisting}

In the above example,
we are allowed to give the type $\forall((T_0) \to T_0)$ to the function \texttt{id},
even though the subexpression \texttt{x + 0} on line 3
would normally impose a type constraint on \texttt{x}
to be addable.

This is because line 3 is ``protected'' by the predicate test \texttt{is\_number(x)},
which allows the variable \texttt{x} on line 3
to have the more specific type $\Number$.

To make this tractable for type checking,
``predicate tests'' can only be of the form
\[ x(y) \]
where both $x$ and $y$ are identifiers.
Furthermore, $x$ must be of a predicate type in the current type environment.

We can make this idea more concrete with the following rule for illustration purposes.
The actual rules we will use are a little more complex.

\noindent
\[
  \Rule{
  \begin{array}{c}
  \Gamma(x) = \Pred(t_{check})
  \\
  x \text{ and } y \text{ are names}
  \\
  (\Sigma_0 \wedge t_{ynew} = \textit{fresh}(t_{check})) = \Sigma_1 \qquad
  \Sigma_1, \Gamma [ y \leftarrow t_{ynew} ] \vdash E_1^{t_1} : \Sigma_2
  \\
  \Sigma_2, \Gamma \vdash E_2^{t_2} : \Sigma_3
  \\
  (\Sigma_3 \wedge t_1 = t_2 \wedge t_2 = t) = \Sigma_{4}
  \end{array}
  }{
  \Sigma_0, \Gamma \vdash ( (x^{t_x}(y^{t_y}))^{t_0}\ \ThenOp\ E_1^{t_1}\ \ElseOp\ E_2^{t_2})^t\ :\ \Sigma_4}
  \begin{array}{l}
  \text{ (for illustration} \\
  \text{purposes only)}
  \end{array}
\]

This rule is only able to handle expressions of the form
$x(y)\ \ThenOp\ E_1\ \ElseOp\ E_2$,
but we would like to be able to also handle
conjunctions of predicate tests
(possibly with other arbitrary boolean expressions)
such as
$x_1(y_1)\ \AndOp\ E_0\ \AndOp\ x_2(y_2)\ \AndOp\ x_3(y_3)\ \ThenOp\ E_1\ \ElseOp\ E_2$.

In such cases, we know that whenever the entire condition evaluates to true,
then the 3 predicate tests nested within all necessarily evaluate to true.
Thus, we should be able to apply all 3 predicate tests to the type environment
when type checking $E_1$.

It is worth noting that the special handling of
certain boolean expressions of predicate tests
we're about to define
have only been added for programmer convenience,
as there are usually ways to ``desugar''
these more complex boolean expressions into nested conditional expressions
in a way that results in the same predicate tests being applied.

To facilitate this, we define two functions,
\ExtractPos\ and \ExtractNeg,
which given an expression and type environment,
will each return a set of predicate tests.
\ExtractPos\ will return all predicate tests that necessarily evaluate to true
whenever the given expression evaluates to true.
\ExtractNeg\ will instead return all predicate tests that necessarily evaluate to true
whenever the given expression evaluates to false.

\[
\Rule
{}
{\ExtractPos_\Gamma(E) = \emptyset}
\begin{array}{c}
\text{where $E$ is neither} \\
\text{of the form $E1$ \AndOp\ $E2$} \\
\text{nor of the form \texttt{!}$E1$} \\
\text{nor a predicate test in the type environment $\Gamma$}
\end{array}
\]

\[
\Rule
{}
{\ExtractNeg_\Gamma(E) = \emptyset}
\begin{array}{c}
\text{where $E$ is neither} \\
\text{of the form $E1$ \OrOp\ $E2$} \\
\text{nor of the form \texttt{!}$E1$} \\
\end{array}
\]

\[
\Rule
{\Gamma(x) = \Pred(t_{check}) \qquad x \text{ and } y \text{ are names}}
{\ExtractPos_\Gamma(x(y)) = \{(y, t_{check})\}}
\]

Note that the rule above defines what is meant by predicate test.

\[
\Rule
{\ExtractPos_\Gamma(E_0) = S_0 \qquad \ExtractPos_\Gamma(E_1) = S_1 \qquad S_0 \cup S_1 = S}
{\ExtractPos_\Gamma(E_0\ \AndOp\ E_1) = S}
\]

\[
\Rule
{\ExtractNeg_\Gamma(E_0) = S_0 \qquad \ExtractNeg_\Gamma(E_1) = S_1 \qquad S_0 \cup S_1 = S}
{\ExtractNeg_\Gamma(E_0\ \OrOp\ E_1) = S}
\]

\[
\Rule
{\ExtractNeg_\Gamma(E) = S}
{\ExtractPos_\Gamma(\texttt{!}\ \texttt{(}\ E\ \texttt{)}) = S}
\qquad
\Rule
{\ExtractPos_\Gamma(E) = S}
{\ExtractNeg_\Gamma(\texttt{!}\ \texttt{(}\ E\ \texttt{)}) = S}
\]

Now we may define the following rule for conditional expressions involving predicate tests.

\[
  \Rule{
  \begin{array}{c}
  \ExtractPos_\Gamma(E_0) = \{ (y_0, t_{check_0}), (y_1, t_{check_1}), \ldots \}
  \text{ is nonempty}
  \\
  (\Sigma_0
  \wedge t_0 = \Bool
  ) = \Sigma_1
  \qquad
  \Sigma_1, \Gamma \vdash E_0^{t_0} : \Sigma_2
  \\
  (\Sigma_2
  \wedge t_{newy_0} = \textit{fresh}(t_{check_0})
  \wedge t_{newy_1} = \textit{fresh}(t_{check_1})
  \wedge \ldots
  ) = \Sigma_3
  \\
  \Sigma_3, \Gamma [ y_0 \leftarrow t_{newy_0} ][ y_1 \leftarrow t_{newy_1} ]\ldots \vdash E_1^{t_1} : \Sigma_4
  \\
  \Sigma_4, \Gamma \vdash E_2^{t_2} : \Sigma_5
  \\
  (\Sigma_5 \wedge t_1 = t_2 \wedge t_2 = t) = \Sigma_{6}
  \end{array}
  }{
  \Sigma_0, \Gamma \vdash ( E_0^{t_0}\ \ThenOp\ E_1^{t_1}\ \ElseOp\ E_2^{t_2})^t\ :\ \Sigma_6}
\]

To handle situations where the condition expression has been negated,
rather than giving up immediately due to having no extractable predicate tests,
we will attempt to typecheck it with the consequent and alternate flipped.

\[
\Rule{
  \ExtractPos_\Gamma(E_0) \text{ is nonempty}
  \qquad
  \Sigma_0, \Gamma \vdash ( E_0^{t_0}\ \ThenOp\ E_2^{t_2}\ \ElseOp\ E_1^{t_1})^t\ :\ \Sigma_1
}{
  \Sigma_0, \Gamma \vdash ( \texttt{!}\ \texttt{(}\ E_0^{t_0}\ \texttt{)}\ \ThenOp\ E_1^{t_1}\ \ElseOp\ E_2^{t_2})^t\ :\ \Sigma_1
}
\]

In the event that a conditional expression involves no predicate tests,
we will type it the usual way with the following rule:

\[
\Rule
{
  \begin{array}{c}
  \ExtractPos_\Gamma(E_0) \text{ is empty}
  \qquad
  \ExtractNeg_\Gamma(E_0) \text{ is empty}
  \\
  (\Sigma_0 \wedge t = t_1), \Gamma \vdash E_0^{t_0} : \Sigma_1 \qquad
  (\Sigma_1 \wedge t_0 = \Bool) = \Sigma_2
  \\
  \Sigma_2, \Gamma \vdash E_1^{t_1} : \Sigma_3 \qquad
  \Sigma_3, \Gamma \vdash E_2^{t_2} : \Sigma_4 \qquad
  (\Sigma_4 \wedge t_1 = t_2) = \Sigma_5
  \end{array}
}{
  \Sigma_0, \Gamma \vdash (E_0^{t_0}\ \ThenOp\ E_1^{t_1}\ \ElseOp\ E_2^{t_2})^t\ :\ \Sigma_5
}
\]

\noindent
The type of conditional statements is similar to the type of conditional expressions.
\[
  \Rule{
  \begin{array}{c}
  \ExtractPos_\Gamma(E_0) = \{ (y_0, t_{check_0}), (y_1, t_{check_1}), \ldots \}
  \text{ is nonempty}
  \\
  (\Sigma_0
  \wedge t_0 = \Bool
  ) = \Sigma_1
  \qquad
  \Sigma_1, \Gamma \vdash E_0^{t_0} : \Sigma_2
  \\
  (\Sigma_2
  \wedge t_{newy_0} = \textit{fresh}(t_{check_0})
  \wedge t_{newy_1} = \textit{fresh}(t_{check_1})
  \wedge \ldots
  ) = \Sigma_3
  \\
  \Sigma_3, \Gamma [ y_0 \leftarrow t_{newy_0} ][ y_1 \leftarrow t_{newy_1} ]\ldots \vdash \{S_1\}^{t_1} : \Sigma_4
  \\
  \Sigma_4, \Gamma \vdash \{S_2\}^{t_2} : \Sigma_5
  \\
  (\Sigma_5 \wedge t_1 = t_2 \wedge t_2 = t) = \Sigma_{6}
  \end{array}
  }{
  \Sigma_0, \Gamma \vdash (\If\ \texttt{(}\ E_0^{t_0}\ \texttt{)\ \{}\ S_1\ \texttt{\}}^{t_1}\ \Else\ \texttt{\{}\ S_2\texttt{ \}}^{t_2})^t\ :\ \Sigma_6}
\]

\[
\Rule{
  \ExtractPos_\Gamma(E_0) \text{ is nonempty}
  \qquad
  \Sigma_0, \Gamma \vdash (\If\ \texttt{(}\ E_0^{t_0}\ \texttt{) \{}\ S_1\ \texttt{\}}^{t_1}\ \Else\ \texttt{\{}\ S_2\texttt{ \}}^{t_2})^t\ :\ \Sigma_1
}{
  \Sigma_0, \Gamma \vdash (\If\ \texttt{(\ !\ (}\ E_0^{t_0}\ \texttt{)\ )\ \{}\ S_1\ \texttt{\}}^{t_1}\ \Else\ \texttt{\{}\ S_2\texttt{ \}}^{t_2})^t\ :\ \Sigma_1
}
\]

\[
\Rule
{
  \begin{array}{c}
  \ExtractPos_\Gamma(E_0) \text{ is empty}
  \qquad
  \ExtractNeg_\Gamma(E_0) \text{ is empty}
  \\
  (\Sigma_0 \wedge t = t_1), \Gamma \vdash E_0^{t_0} : \Sigma_1 \qquad
  (\Sigma_1 \wedge t_0 = \Bool) = \Sigma_2
  \\
  \Sigma_2, \Gamma \vdash \{S_1\}^{t_1} : \Sigma_3 \qquad
  \Sigma_3, \Gamma \vdash \{S_2\}^{t_2} : \Sigma_4 \qquad
  (\Sigma_4 \wedge t_1 = t_2) = \Sigma_5
  \end{array}
}{
  \Sigma_0, \Gamma \vdash (\If\ \texttt{(}\ E^{t_0}\ \texttt{)\ \{}\ S_1\ \texttt{\}}^{t_1}\ \Else\ \texttt{\{}\ S_2\texttt{ \}}^{t_2})^t\ :\ \Sigma_5
}
\]


\section{Type Safety of Source}
\label{simplsafe}

Now we can define what it means for a statement to be well-typed. 

\begin{definition}
A statement $S$ is
well-typed, if there is a consistent type constraint $\Sigma$ such that $S: \Sigma$.
\end{definition}

Note that this definition
of well-typedness requires that a well-typed statement has no free 
names.

%% The following property of the typing relation are useful for 
%% reasoning on types. 
%% %
%% \begin{lemma}
%% Typing is not affected by ``junk'' in the type assignment. 
%% If $\Sigma, \Gamma \vdash S:\Sigma'$, and $\Sigma, \Gamma \subset \Gamma'$, then 
%% $\Sigma, \Gamma' \vdash S: \Sigma'$. 
%% \end{lemma}


%% \begin{definition}
%% A programming language with a given typing relation 
%% $\cdots \vdash\cdots :\cdots$ and one-step evaluation 
%% $\mapsto$ is called type-safe, if the following two conditions hold: 
%% \begin{enumerate}
%% \item {\bf Preservation.} If $S$ is a well-typed program 
%% with respect to $\cdots \vdash \cdots :\cdots$ and 
%% $S \mapsto S'$, then $S'$ is also a 
%% well-typed program with respect to $\vdash$. 
%% \item {\bf Progress.} If $S$ is a well-typed program, 
%% then either $S$ is a value or there exists a program $S'$ 
%% such that $S \mapsto S'$. 
%% \end{enumerate}
%% \end{definition}
%% %
%% Is Typed Source type-safe? 
%% Neither preservation nor progress can hold without some 
%% assumptions on the primitive operations of the given 
%% language. For preservation, 
%% we must assume that if the result of applying
%% an operation $p$ to arguments $v_1,\ldots, v_n$ is $v$ 
%% and $p[v_1,\ldots,v_n] : t$ then $v:t$. Fortunately,
%% this is the case for all operators of the language Typed Source.

%% \begin{theorem}[Preservation]
%% If for a Typed Source program $S$ and some type $t$ holds $S:t$ 
%% and if $S \mapsto_{\textrm{Typed Source}} S'$, then $S':t$. 
%% \end{theorem}

%% \begin{proof}
%% The proof could proceed by structural induction on the 
%% rules defining Typed Source.
%% \end{proof}

%% \begin{lemma}[Canonical Forms]
%% Suppose that the Typed Source expression 
%% $v$ is a closed, well-typed value and $v:t$. 
%% \emph{
%% \begin{enumerate}
%% \item If $t=\Bool$, then either $v=\TruE$ or $v=\FalsE$. 
%% \item If $t=\Int$, then $v=n$ for some $n$. 
%% \item If $t=t_1\Times\cdots\Times t_n\ \Right\ t'$, then\\
%% $v= \Lp x_1,\ldots, x_n\Rp\ \texttt{=>}\ \Lc\ S\ \Rc$,\\
%% for some $x_1,\ldots,x_n$ and $S$.
%% \end{enumerate}}
%% \end{lemma}
%% %
%% \begin{proof} (Sketch)
%% The proof could proceed by inspection of the typing rules.
%% For example for the first expression, we look at all rules that assign
%% types to values (TrueT, FalseT, NumT, FunT and RecFunT), and find that
%% the only cases where the type is $\Bool$ are TrueT and FalseT.
%% \end{proof}

%% For progress, 
%% we must assume that if $p[v_1,\ldots,v_n]$ is well-typed, 
%% then there exists a value $v$
%% such that $v$ is the result of applying $p$ to the 
%% arguments $v_1,\ldots,v_n$. This means that primitive 
%% operations are not allowed to be undefined on some arguments.
%% Unfortunately, this is not the case for all operators of
%% Typed Source. 
%% Division is not defined on 0 as first argument.
%% So, let Typed Source' be the result of restricting Typed Source by excluding
%% integer division from the set of primitive operators.

%% \begin{theorem}[Progress]
%% If for a Typed Source' statement $S$ holds $S:t$ for some type $t$, 
%% then either $S$ is a value, or there exists a statement
%% $S'$ such that $S \mapsto_{\textrm{Typed Source'}} S'$. 
%% \end{theorem}

%% \begin{proof} (Sketch)
%% The proof would be by induction on the rules defining Typed Source'.
%% \end{proof}

%% \noindent
%% The type safety of Typed Source' ensures that evaluation of a
%% well-typed Typed Source' expression ``behaves properly'', which
%% means does not get stuck.
%% Can we say the reverse by claiming that any expression
%% for which the dynamic semantics produces 
%% a value is well-typed? If this was the case,
%% the type system for Typed Source' would do a perfect job by 
%% statically identifying exactly those Typed Source' expressions 
%% that get stuck. Unfortunately, this is not the
%% case. A simple counter-example is the statement
%% \begin{verbatim}
%% true ? 1 : false;
%% \end{verbatim}
%% This statement evaluates to \verb#1#, but is not well-typed.
%% In Chapter~12, we shall see that it is not possible to
%% have a perfect type system for languages like Typed Source' (or Typed Source).

\end{document}
