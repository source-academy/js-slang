% Created 2020-03-31 Tue 14:15
% Intended LaTeX compiler: pdflatex
\input{source_header.tex}
\newcommand{\qed}{$\Box$}
\newcommand{\Rule}[2]{\genfrac{}{}{0.7pt}{}{{\setlength{\fboxrule}{0pt}\setlength{\fboxsep}{3mm}\fbox{$#1$}}}{{\setlength{\fboxrule}{0pt}\setlength{\fboxsep}{3mm}\fbox{$#2$}}}}
\newcommand{\Rulee}[3]{\genfrac{}{}{0.7pt}{}{{\setlength{\fboxrule}{0pt}\setlength{\fboxsep}{3mm}\fbox{$#1$}}}{{\setlength{\fboxrule}{0pt}\setlength{\fboxsep}{3mm}\fbox{$#2$}}}[#3]}
\newcommand{\transition}{\rightrightarrows_s}
\newcommand{\translate}{\twoheadrightarrow}
\newcommand{\translateaux}{\hookrightarrow}
\usepackage[strings]{underscore}
\usepackage[title]{appendix}
\author{koo}
\date{\today}
\title{}
\hypersetup{
 pdfauthor={koo},
 pdftitle={},
 pdfkeywords={},
 pdfsubject={},
 pdfcreator={Emacs 26.3 (Org mode 9.2.6)},
 pdflang={English}}

\renewcommand{\docheader}[3]{%

  \thispagestyle{empty}

\markright{SICP, JavaScript Adaptation, #2 #3, #1}
\begin{center}
  {\Large {\bf Specification of #2 #3}---#1 edition}\\[10mm]

  {\large Jonathan Chan Wai Hon and Zhengqun Koo}\\[5mm]

  {\large National University of Singapore \\
          School of Computing}\\[10mm]

  {\large \today}\\[10mm]
\end{center}
}
\begin{document}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\docheader{2021}{Source}{\S 3 Concurrent}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\input{source_intro.tex}
\section{Introducing Concurrency to Source}
\label{sec:org2ac2c7f}
This concurrent system consists of concurrently executing (potentially multiple) code in multiple threads. Communication between threads is achieved by updating the values of memory shared between threads. Each thread is a collection of registers \(\textit{os}, \textit{pc}, \textit{e}, \textit{rs}\), and at the expiration of the time quantum, the concurrent system executes the next thread in the thread queue.
To comply with the textbook, the thread that calls \texttt{concurrent\_execute} also continues to execute the rest of its code concurrently with the threads. Furthermore, there is no \texttt{join} primitive concurrent function.

Compared to Source \(\S 3\), this concurrent system has the following changes:
\begin{itemize}
\item The addition of three primitive concurrent functions.
\end{itemize}
For details, see Section ``Concurrency Support'' below.

\section{Concurrency Support}
\label{sec:orge505f00}
The following concurrent functions are supported:
\begin{itemize}
\item \(\texttt{concurrent_execute(}\texttt{f}_\texttt{1}, \cdots \texttt{f}_\texttt{n}\texttt{)}\): \(\textit{primitive}\), setup multiple threads for concurrent execution. For each nullary function \(\texttt{f}_\texttt{i}\) that returns \texttt{undefined}, setup a thread \(\texttt{t}_\texttt{i}\) that executes the code in the body of \(\texttt{f}_\texttt{i}\). The thread that called \texttt{concurrent\_execute} also executes concurrently with all \(\texttt{t}_\texttt{i}\). Returns \texttt{undefined}. This is an atomic operation.
\item \texttt{test\_and\_set(a)}: \(\textit{primitive}\), assumes the head of array \texttt{a} is a boolean \(b\). Sets the head of \texttt{a} to \texttt{true}. Returns \(b\). This is an atomic operation.
\item \texttt{clear(a)}: \(\textit{primitive}\), sets the head of array \texttt{a} to \texttt{false}. Returns \texttt{undefined}. This is an atomic operation.
\end{itemize}

\section{Under the hood: a Virtual Machine for Concurrent Source}
\label{sec:org1d2bc50}
In this specification, we describe the behavior of compiling from Source to SVML, as well as running SVML, with natural deduction rules. Please refer to \hyperref[sec:org72fc34e]{Appendix A} for explanations about compilation rules and VM transition rules.

\subsection{\texttt{EXECUTE} Rules}
\label{sec:org2e43dfb}

\subsubsection{Compiling}
\label{sec:org2f52610}
$$\Rule{E_1 \translateaux s_1 \qquad \cdots \qquad E_n \translateaux s_n}{\texttt{concurrent_execute}(E_1, \cdots , E_n) \translateaux s_1. \cdots .s_n.\texttt{CALLV id n}}$$
Each of \(s_1. \cdots .s_n\) is a sequence of VM instructions that loads a closure onto the operand stack, and \(id\) is the opcode of \texttt{EXECUTE}.

\subsubsection{Running}
\label{sec:orgfebc362}
The state representing a normal VM has these structures:
$$(\textit{os}, \textit{pc}, \textit{e}, \textit{rs})$$
There are additional structures in our VM:
\begin{enumerate}
\item \(\textit{tq}\), a register which is a queue of threads.
\item \(\textit{to}\), a register initialized with \(0\), that indicates how many instructions are left for a thread to run.
\end{enumerate}
The state representing our VM will have two more corresponding structures:
$$(\textit{os}, \textit{pc}, \textit{e}, \textit{rs}, \textit{tq}, \textit{to})$$
The initial state of our VM is a \(\textit{pc}\) set to zero, and has empty \(\textit{os}\), \(\textit{env}\), \(\textit{rs}\), and \(\textit{tq}\), and zero timeout:
$$(\langle \rangle, 0, \langle \rangle, \langle \rangle, \langle \rangle, 0)$$

Some notes on program execution:
\begin{enumerate}
\item When the program calls \texttt{concurrent\_execute}, it executes the rest of its code along with the concurrent threads, therefore the sequential program becomes a concurrent thread.
\item Consider the case when a program does not use any primitive concurrent functions. To avoid distinguishing between the case when the program is sequential and the program is concurrent, therefore simplifying the rules, the sequential program must still execute like a concurrent thread. This means sequential execution may time out, and may be pushed and popped from the thread queue. However, implementations of the VM may, as an optimization, avoid pushing and popping while executing sequential code.
\item As a result, all programs here are concurrent programs, even if they do not call \texttt{concurrent\_execute}.
\item None of the programs here return a result, because concurrent programs should not return a result, since concurrent threads return nothing.
\end{enumerate}

Design choices:
\begin{enumerate}
\item Threads are scheduled in a round-robin manner, where the order of threads in the circular queue is respected, and all threads are scheduled some time to execute (this scheduled time is also known as the timeout of a thread), so resource starvation is impossible.
\item We modify the round-robin scheduler, by allocating a random timeout to each thread, so that different runs of the same program are more likely to execute differently, for a more interesting experience. This preserves the impossibility of resource starvation.
\end{enumerate}

\paragraph{Thread timeout}
\label{sec:org760382b}
$$\Rule{}{
\begin{aligned}
&(\textit{os}_1, \textit{pc}_1, \textit{e}_1, \textit{rs}_1, (\textit{os}_2, \textit{pc}_2, \textit{e}_2, \textit{rs}_2).\textit{tq}, 0)\\
\transition &(\textit{os}_2, \textit{pc}_2, \textit{e}_2, \textit{rs}_2, \textit{tq}.(\textit{os}_1, \textit{pc}_1, \textit{e}_1, \textit{rs}_1), c)
\end{aligned}}$$
If a thread times out and has not finished execution (has not executed the \texttt{RET} statement), then it is enqueued on the thread queue, and the next thread is dequeued from the thread queue, with a random timeout value \(c\).

The above rule assumes there is least one thread in the thread queue. To cover all cases, here is the rule for zero threads in the thread queue:
$$\Rule{}{(\textit{os}, \textit{pc}, \textit{e}, \textit{rs}, \langle \rangle, 0) \transition (\textit{os}, \textit{pc}, \textit{e}, \textit{rs}, \langle \rangle, c)}$$

\paragraph{Running thread}
\label{sec:org0f4af5f}
$$\Rule{s(\textit{pc}) \neq \texttt{RET} \qquad \textit{to} > 0}{(\textit{os}, \textit{pc}, \textit{e}, \textit{rs}, \textit{tq}, \textit{to}) \transition (\textit{os'}, \textit{pc'}, \textit{e'}, \textit{rs'}, \textit{tq}, \textit{to}-1)}$$
where the primed values are just like normal VM code execution, and the timeout is initially nonzero, and then decrements.

\paragraph{Running thread, returning from function}
\label{sec:org09fb933}
$$\Rule{s(\textit{pc}) = \texttt{RET} \qquad \textit{to} > 0 \qquad \textit{rs} \neq \langle \rangle}{(\textit{os}, \textit{pc}, \textit{e}, \textit{rs}, \textit{tq}, \textit{to}) \transition (\textit{os'}, \textit{pc'}, \textit{e'}, \textit{rs'}, \textit{tq}, \textit{to}-1)}$$
where the primed values are just like normal VM code execution, and the timeout is initially nonzero, and then decrements. Note: the thread may execute the \texttt{RET} statement inside a function, and the thread does the normal thing of popping \(\textit{rs}\) and so on.

\paragraph{Starting \texttt{EXECUTE}}
\label{sec:orgd950fad}
$$\Rule{s(\textit{pc}) = \texttt{EXECUTE n} \qquad \textit{to} > 0}{
\begin{aligned}
&((\textit{pc}_1, \textit{e}_1). \cdots .(\textit{pc}_n, \textit{e}_n).\textit{os}, \textit{pc}, \textit{e}, \textit{rs}, \langle \rangle, \textit{to})\\
\transition &(\textit{os}, \textit{pc}, \textit{e}, \textit{rs}, (\langle \rangle, \textit{pc}_1, \textit{e}_1, \langle \rangle). \cdots .(\langle \rangle, \textit{pc}_n, \textit{e}_n, \langle \rangle), \textit{to}-1)
\end{aligned}}$$
Closures representing threads \(t_i\) (two-tuples of \(\textit{pc}_i\) and \(\textit{e}_i\)) on the operand stack are converted into threads \(t_i\). Thread \(t_i\) is a four-tuple of each thread \(t_i\)'s own \(\textit{os}_i\), \(\textit{pc}_i\), \(\textit{e}_i\), and \(\textit{rs}_i\). Initially, thread \(t_i\) has empty \(\textit{os}_i\) and empty \(\textit{rs}_i\).
The thread that calls \texttt{concurrent\_execute} also continues to execute concurrently with the other threads. This is shown by the \(\textit{os}, \textit{pc}, \textit{e}, \textit{rs}\) being in the machine state after the transition arrow, and shown by the timeout decrementing.
Note: we decrement timeout instead of setting a random timeout, since setting a random timeout makes starvation possible: the thread that only calls \texttt{concurrent\_execute}, and calls \texttt{concurrent\_execute} infinitely many times, will always be run.

\paragraph{Returning from thread}
\label{sec:orgd59f2a1}
$$\Rule{s(\textit{pc}_1) = \texttt{RET} \qquad \textit{to} > 0 \qquad \textit{rs}_1 = \langle \rangle}{(\textit{os}_1, \textit{pc}_1, \textit{e}_1, \textit{rs}_1, (\textit{os}_2, \textit{pc}_2, \textit{e}_2, \textit{rs}_2).\textit{tq}, 0) \transition (\textit{os}_2, \textit{pc}_2, \textit{e}_2, \textit{rs}_2, \textit{tq}, c)}$$
If a thread executes the \texttt{RET} statement, and the runtime stack is empty, then the thread is not enqueued on the thread queue, and the next thread is dequeued from the thread queue, with a random timeout value \(c\).

The above rule assumes there is least one thread in the thread queue. To cover all cases, the rule for zero threads in the thread queue is in the next subsection:

\paragraph{Ending our VM}
\label{sec:org2f2aa7e}
$$\Rule{s(\textit{pc}) = \texttt{RET} \qquad \textit{to} > 0 \qquad \textit{rs} = \langle \rangle \qquad \textit{tq} = \langle \rangle}{(\textit{os}, \textit{pc}, \textit{e}, \textit{rs}, \textit{tq}, \textit{to}) \transition (\textit{os}, \textit{pc}, \textit{e}, \textit{rs}, \textit{tq}, \textit{to}-1)}$$
If a thread executes the \texttt{RET} statement, and both the runtime stack and the thread queue are empty, and the timeout is nonzero, then the timeout decrements, and our VM stops.

\subsection{\texttt{TEST\_AND\_SET} and \texttt{CLEAR} Rules}
\label{sec:org5150a20}

\subsubsection{Compiling}
\label{sec:org679b438}
$$\Rule{E \translateaux s}{\texttt{test_and_set}(E) \translateaux s.\texttt{CALLV id 1}}$$
where \(E\) is an array, whose head is a boolean, and \(id\) is the opcode of \texttt{TEST\_AND\_SET}.

$$\Rule{E \translateaux s}{\texttt{clear}(E) \translateaux s.\texttt{CALLV id 1}}$$
where \(E\) is an array, and \(id\) is the opcode of \texttt{CLEAR}.

\subsubsection{Running}
\label{sec:org75cbeca}
$$\Rule{s(\textit{pc}) = \texttt{TEST_AND_SET}}{(a.\textit{os},\textit{pc}) \transition (b.\textit{os},\textit{pc} + 1)}$$
where \(a\) is the address of an array stored on the heap. The head of this array is initially \(b\), where \(b\) is a boolean. After this rule executes, the head of this array is set to \(\textit{true}\).

$$\Rule{s(\textit{pc}) = \texttt{CLEAR}}{(a.\textit{os},\textit{pc}) \transition (\textit{os},\textit{pc} + 1)}$$
where \(a\) is the address of an array stored on the heap. The head of this array is updated to \(\textit{false}\).

\begin{appendices}
\section{Explanations on Inference Rules}
\label{sec:orgd804cd9}

\subsection{Inference Line}
\label{sec:org5ed4f60}
The horizontal inference line plays the role of \(\texttt{if } \ldots \texttt{then } \ldots\) in our earlier presentations of the rules. In general, in an inductive definition of a set \(X\), an inference rule of the form
$$\Rule{x_1 \quad \cdots \quad x_n}{x}$$
stands for the rule \(\texttt{if } x_1 \ldots x_n\in X \texttt{, then }x \in X\).

\subsection{Compilation Rules}
\label{sec:org0e2d22d}
The translation from Source to SVML is accomplished by a function
$$\translate: \textrm{Source} \rightarrow \textrm{SVML}$$
which uses the auxilary translation function \(\translateaux\).

The auxiliary translation function \(\translateaux\) is defined by many rules, some of which we have already covered in this document: the rules for \texttt{concurrent\_execute}, \texttt{test\_and\_set}, and \texttt{clear}.
The other rules for the auxiliary translation function \(\translateaux\) will not be covered in this document. Instead, please refer to the document \href{svml-spec.pdf}{Source Virtual Machine Language}.

\subsection{VM Transition Rules}
\label{sec:org7e77008}
The machine that we will use to execute SVML programs is a variation of a \emph{push-down automaton}. Let us fix a specific program \(s\). The machine \(M_s\) that executes \(s\) is given as an automaton that transforms a given machine state to another state. The machine state is represented by so-called registers.
In the case of SVML, we need four registers:
\begin{description}
\item[{operand stack}] denoted by the symbol \textit{os}
\item[{program counter}] denoted by the symbol \textit{pc}
\item[{environment}] denoted by the symbol \textit{e}
\item[{runtime stack}] denoted by the symbol \textit{rs}
\end{description}
The initial state of a VM is a \(\textit{pc}\) set to zero, and empty \(\textit{os}\), \(\textit{env}\), \(\textit{rs}\):
$$(\langle \rangle, \textit{pc}, \langle \rangle, \langle \rangle)$$

\subsubsection{\(\textit{pc}\): Program Counter}
\label{sec:org92c6cf6}
The program counter is used to point to a specific instruction in \(s\), starting from position 0.
For example, if \(\textit{pc} = 2\), and \(s\) is the program
$$\begin{aligned}
\lbrack&\texttt{LGCI 2},\\
&\texttt{LGCI 1},\\
&\texttt{SUBG},\\
\rbrack
\end{aligned}$$
, then \(s(\textit{pc}) = \texttt{SUBG}\).

\subsubsection{\(\textit{os}\): Storing of Intermediate Values}
\label{sec:orgb219984}
The operand stack is a sequence of boxed values holding values during an execution. These values are separated by the character \$.\$.
For example, \(\textit{os} = 10.20.\textit{true}\) represents an operand stack with \(10\) on top, followed by \(20\), followed by \(\textit{true}\).

Now, we can describe the behavior of the machine \(M_s\) as a transition function \(\transition\), which transforms machine states to machine states, and which is defined by many rules.

The load instructions simply push their value on the operand stack. Here is one such load instruction, \texttt{LGCI}:
$$\Rule{s(\textit{pc}) = \texttt{LGCI}\ i}{
(\textit{os},\textit{pc}) \transition (i.\textit{os},\textit{pc}+1)}$$

The remaining rules implement the instructions corresponding to Source's operators. They pop their arguments from the operand stack, and push the result of the operation back onto the operand stack. Here is one such instruction, \texttt{SUBG}:
$$\Rule{s(\textit{pc}) = \texttt{SUBG}}{
(i_2.i_1.\textit{os},\textit{pc}) \transition (i_1-i_2.\textit{os},\textit{pc}+1)}$$

Note that the \texttt{SUBG} instruction subtracts the top element of the stack from the element below, because the subtrahend will be the most recently computed value and therefore appears on top of the stack, whereas the minuend has been computed before the subtrahend, and thus appears below it on the stack.

\subsubsection{\(\textit{e}\): Compilation and Execution of Names}
\label{sec:org7af6a82}
We implement names by environments. To this aim, we add a register \(e\) to the machine state. Register \(e\) represents the environment with respect to which the names are executed. Environments map indexes of names to denotable values. Thus an environment \(e\), in which \(i\) is the index of the variable name that refers to the number \(1\) can be accessed by applying \(e\) to \(i\), \(e(i) = 1\).

Names in environments are compiled away to become indexes in environments. For example:

Assignments to name \(x\) in Source are translated to instructions \(\texttt{STLG}\ i\):
$$\Rule{}{x = v \translateaux \texttt{STLG}\ i}$$
where \(i\) is the index of the stored value in the current environment, and \(v\) is the stored value.

Occurrences of name \(x\) in Source are translated to instructions \(\texttt{LDLG}\ i\):
$$\Rule{}{x \translateaux \texttt{LDLG}\ i}$$
where \(i\) is the index of the stored value in the current environment.

Assignments to names assigns the value on the operand stack to the name. Thus, the rule specifying the behavior of \(\texttt{STLG}\ i\) is as follows:

$$\Rule{s(\textit{pc}) = \texttt{STLG}\ i}{
(v.\textit{os},\textit{pc},e) \transition (\textit{os},\textit{pc}+1,e')}$$
where \(e'\) is the same as \(e\) for all indexes other than \(i\), and \(e'(i) = v\).

The execution of name occurrences pushes the value to which the name refers on the operand stack. Thus, the rule specifying the behavior of \(\texttt{LDLG}\ i\) is as follows:

$$\Rule{s(\textit{pc}) = \texttt{LDLG}\ i}{
(\textit{os},\textit{pc},e) \transition (e(i).\textit{os},\textit{pc}+1,e)}$$

\subsubsection{\(\textit{rs}\): Execution of Function Application}
\label{sec:org837eb1c}
According to the translation of function application, the instruction \(\texttt{CALL}\ n\) will find its arguments in reverse order on the operand stack, followed by the operator, which---according the the previous paragraph---is represented by a closure. To implement static scoping, the machine must take the environment of the closure, and extend it by a binding of the formal parameters to the actual arguments. Thus, the following rule is our first attempt to describe the execution of \(\texttt{CALL } n\).

$$\Rule{s(\textit{pc}) = \texttt{CALL } n}{
\begin{aligned}
&(v_n.\ldots v_1.(\textit{address},x_1\cdots x_n,e').\textit{os},\textit{pc},e)\\
\transition &(\textit{os},\textit{address},e'[x_1 \leftarrow v_1]\cdots[x_n \leftarrow v_n])
\end{aligned}}$$

There is, however, a major difficulty with this rule. What should happen when a function returns? In other words, what should the machine do when it encounters the instruction \(\texttt{RTN}\) after executing the function body? In particular, what should be the program counter, operand stack and environment after returning from a function? Of course, the program counter, operand stack and environment must be restored to their state before the function call.

In order to keep program execution in a simple loop, we need to make this return information explicit. Since functions can call other functions before returning, the natural data structure for this return information is a stack. We call this stack the \emph{runtime stack}. The runtime stack, denoted by \(\textit{rs}\), will be the forth (and last) register that we add to our machine state. Each entry in the runtime stack contains the \(\textit{address}\) of the instruction to return to, and the operand stack \(\textit{os}\) and environment \(e\) to be reinstalled after the function call. Such a triplet \((\textit{address},\textit{os},e)\) is called \emph{runtime stack frame}, or simply \emph{stack frame}.

Function application pushes a new stack frame on the runtime stack, in addition to the actions described in the first attempt above. Thus, the actual rule for \(\texttt{CALL}\ n\) is as follows.

$$\Rule{s(\textit{pc}) = \texttt{CALL } n}{
\begin{aligned}
&(v_n.\ldots v_1.(\textit{address},x_1\cdots x_n,e').\textit{os},\textit{pc},e,\textit{rs})\\
\transition &(\langle \rangle,\textit{address},e'[x_1 \leftarrow v_1]\cdots[x_n \leftarrow v_n],(\textit{pc}+1,\textit{os},e).\textit{rs})
\end{aligned}}$$

Now, we can describe the behavior of the machine \(M_s\) as a transition function \(\transition\), which transforms machine states to machine states, and which is defined by many rules, some of which we have already covered in this document: the rules for \texttt{EXECUTE}, \texttt{TEST\_AND\_SET}, and \texttt{CLEAR}.
The other rules for the transition function \(\transition\) will not be covered in this document. Instead, please refer to the document \href{svml-is.pdf}{Source VM Instruction Set}.
\end{appendices}
\end{document}